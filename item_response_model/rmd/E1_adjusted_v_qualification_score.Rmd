---
title: \vspace{3.5in}"Comparing Adjusted and Original Qualification Score - Experiment-1"
author: "Christian Medeiros Adriano"
date: "`r Sys.Date()`"
bibliography: "..//..//bibtex//rmd_references.bib"
csl: "..//..//bibtex//acm-sig-proceedings.csl"
output:
   pdf_document:
      fig_caption: true
      number_sections: true
---
\newpage
\tableofcontents 
\listoffigures
\listoftables
\newpage 

    
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)

source("C://Users//Christian//Documents//GitHub//CausalModel_FaultUnderstanding//data_loaders//load_consent_create_indexes_E1.R")
df_consent <- load_consent_create_indexes();

```

# About this report

Investigate the impact of the score adjustment on the association between score and the other covariates, e.g, years of experience, age, gender, duration, explanation size, confidence, and accuracy of tasks.

# Comparing Distributions

## How do the distribution overlap?

```{r density plots, echo=FALSE}

#Center (subtract the mean) and Scales (divided by the standard deviation)
qualification_scores <- scale(df_consent$qualification_score, center=TRUE, scale=TRUE)
irt_scores <- scale(df_consent$adjusted_score, center=TRUE, scale=TRUE)

score_type <- rep("original",length(qualification_scores))
original_score_list <- cbind(qualification_scores,score_type)
score_type <- rep("adjusted",length(irt_scores))
irt_score_list <- cbind(irt_scores,score_type)

all_score_list <- rbind(original_score_list,irt_score_list)
df_all_scores <- data.frame(all_score_list)
colnames(df_all_scores) <- c("score","type")
df_all_scores$score <- as.numeric(as.character(df_all_scores$score))

df_all_scores %>%
  ggplot(aes(x=score, fill=type)) +
  #geom_histogram(binwidth=0.05, color="darkgrey", fill="lightblue") +
  geom_density(alpha=0.3)+
  theme_minimal()+
  theme(
    legend.position=c(0.85, 0.90),
    panel.spacing = unit(0.1, "lines"),
    strip.text.x = element_text(size = 12),
    plot.title = element_text(size=14),
    axis.text.x = element_text(angle = 20, hjust = 1, size=12)
  ) +
  xlab("Scores (centered and scaled)") +
  ylab("Frequency") +
  ggtitle("Qualification score distribution E2") 

```

The chart shows that the adjusted score smoothed the distribution,
but still preserved the two general patterns of concentration on 
high and low medium-to-low scores.

However, it also increased the frequency of the lowest score and
highest score groups. The final distribution has more oa an
exponential shape, while the original one had a right skewed Gaussian
shape.


The reason for the smoothing is two-fold: adjusted score is continuous scale and the original shifted some very low scores to a low-to-medium score. The latter
corresponds to giving a lower weight to questions that most people
got it correctly This was the case of question 4.

## Are the distributions statistically significant distinct?
As the distributions do not look normal, which is confirmed by the Shapiro -Wilk normality test (@royston1995shapiro),
I compared their means using the non-parametric kendall-tau test.


## How does the entropy (spread) of the distributions compare?


# Comparing Rankings
## Ranking the participants by their score, how many changed their positions? 

## How do participants who increased their ranking position compare to others w.r.t. their years of experience?

## How do participants who decreased their ranking position compare to others w.r.t. their years of experience?

## Are participants who increased, descreased, not changed ranking positions statistically significant distinct w.r.t. to score and years of experience?

# Comparing Correlation
## Years of programming and Score 
## Age and Score 
## Gender and Score

# References

